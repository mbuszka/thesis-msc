\chapter{The Functional Correspondence}\label{chapter:functional-correspondence}
The functional correspondence between evaluators and abstract machines is a technique for mechanical derivation of an abstract machine from a given evaluator.
The technique was first characterized and described in \cite{functional-correspondence} and then later studied in context of various object-languages and their evaluators in (TODO more references).
The input of the derivation is an evaluator written in some functional meta-language.
It usually corresponds to a variant of denotational semantics (particularly in case of so-called meta-circular interpreters) or big-step operational semantics.
The result of the derivation is a collection of mutually tail-recursive, first-order functions in the same meta-language.
Program in such a form corresponds to an abstract machine.
The different functions (with actual parameters) represent states of the machine, while the function calls specify the transition function.

The derivation consists of two program (in our case interpreter's) transformations: transformation to continuation-passing style and defunctionalization.
The first one exposes the control structure of the evaluator; the second replaces function values with first-order data structures and their applications with calls to a first-order global function.

In the remainder of this chapter I will describe those transformations and illustrate their behavior using the running example of an evaluator for \LC{} from Section \ref{sec:idl}.
The abstract syntax and the corresponding meta-language records are shown in Figure \ref{fig:lambda-calc-stx}.
The variables are represented as \lstinline!String!s of characters.
We will begin with a standard meta-circular interpreter shown in Figure \ref{fig:lambda-calc-interp} and arrive at a variation of the CEK machine.
Since every expression in \LC{} may only evaluate to a function, the values produced by the interpreter are represented as meta-language functions.
The interpreter uses environments represented as partial functions from variables to values to handle binding of values to variables during application.
The application in object-language is interpreted using application in meta-language so the defined language inherits call-by-value, left-to-right evaluation order.

\begin{figure}
  \begin{center}
    \begin{tabular}{r l r}
      \LC & Representation & Name \\
      \hline
      $x$ & \lstinline!String! & Variable \\
      $ \lambda x . e $ & \lstinline!{Abs String Term}! & Abstraction \\
      $ e \, e $ & \lstinline!{App Term Term}! & Application
    \end{tabular}  
  \end{center}
  \caption{\LC{} syntax and its representation}
  \label{fig:lambda-calc-stx}
\end{figure}

\section{Continuation-Passing Style}
The first step towards building the abstract machine is capturing the control-flow characteristics of the defined language.
We are interested in exposing the order in which the sub-expressions are evaluated and how the control is passed from function to function.
Additionally, we would like the resulting program to define a transition system so we must require that every function call in the interpreter is a tail-call.
It turns out that a program in continuation-passing style (CPS) exactly fits our requirements.

What does it mean for a program to be in CPS?
Let us begin by classifying expressions into trivial and serious ones.
An expression is trivial if evaluating it always returns a value.
Since we cannot in general decide whether an arbitrary expression is trivial we will use a safe approximation: an expression is trivial if it is a variable, a function definition, a primitive operation call or a structure constructor with only trivial expressions as sub-terms.
We will only allow applications, match expressions and constructors with trivial sub-expressions.
Additionally we would like to consider some expressions trivial due to their interpretation (e.g. environment lookups) even though they are serious.
In order to retain ability to build interesting programs, every function will accept an additional argument -- a continuation which specifies what should be done next.

The interesting clauses of the algorithm for simple CPS translation of expressions in \IDL{} are presented in Figure \ref{fig:cps-translation}.
The meta variables are typeset with italics (e.g., \textit{k}).
The pieces of syntax use typewriter font (e.g., \texttt{k'}).
The function $ \llbracket e \rrbracket k $ transforms an expression $e$ to continuation-passing-style using expression $k$ as a continuation.
Whenever a new variable is introduced by the algorithm we will assume that it is fresh.
The variable \texttt{x} is translated to application of continuation $k$ to \texttt{x}.
To translate an anonymous function definition, first a fresh variable \texttt{k'} is generated then the body of the function is translated with \texttt{k'} as the continuation and finally, the continuation $k$ is applied to the transformed function expression.
Function application is transformed by placing all sub-expressions in successively nested functions, with the deepest one actually performing the call with an additional argument -- the continuation $k$.
This way the evaluation of arguments is sequenced left-to-right and happens before the application.
Translation of the \texttt{match} expression requires translating the scrutinee and putting the branches in the continuation. The branches are all transformed using the same continuation $k$.
Finally, during translation of the \texttt{error} expression the continuation is discarded since the error halts the execution.
The omitted rules for \texttt{if} expressions and record creation are similar to \texttt{match} expressions and applications respectively.

Figure \ref{fig:lambda-calc-interp-cps} shows the interpreter with body of \lstinline!eval! translated to CPS using the algorithm of Figure \ref{fig:cps-translation} and then hand-optimized by reducing administrative redexes.
The \lstinline!eval! function now takes an additional argument \lstinline!k! -- a continuation.
The function denoting the object-language lambda expressions also expects a continuation.
In both variable and abstraction cases the evaluator now calls the continuation \lstinline!k! with the computed value: either looked up in the environment in case of a variable or freshly constructed in case of abstractions.
The evaluation of applications is now explicitly sequenced.
First the expression in function position will be evaluated.
It is passed a continuation which will then evaluate the argument.
After the argument is computed, the function value will be applied to the argument and the original continuation \lstinline!k! passed by the caller.
The \lstinline!main! function is kept in direct style as it is the entry point of the evaluator.
It calls the \lstinline!eval! function which expects a continuation so it provides it the identity function.
This continuation means that when evaluation is finished it will return the final value.

We can see that after the transformation the evaluation order of the meta-language does not affect the evaluation order of the object-language as every call to the only interesting function \lstinline!eval! is a tail call.
Therefore we have successfully captured control-flow characteristics of the object-language.
The evaluator still technically depends on the order of evaluation of \IDL{} as environment lookup may fail and it is in a sub-expression position but from the point of view of designing an abstract machine which works with closed terms it is not interesting.

In Section \ref{sec:selective-cps} we will see a more complex transformation which avoids creating administrative redexes and allows for user defined functions which should be considered trivial.

\begin{figure}
    \centering
   \begin{align*}
        \llbracket \texttt{x} \rrbracket k =& \texttt{(}k\,\texttt{x)}\\
%
        \llbracket \texttt{(fun (x y ...) e)} \rrbracket k
        =& \texttt{(} k \, \texttt{(fun (x y ... k')}\, \llbracket \texttt{e} \rrbracket \texttt{k'))} \\
%        
        \llbracket \texttt{(}e_1\ldots e_n\texttt{)} \rrbracket k
        =& \llbracket e_1 \rrbracket \, \texttt{(fun (v1)} \ldots \llbracket e_n \rrbracket k' \ldots \texttt{)}\, \\
         & \text{where}\,k' = \texttt{(fun (vn) (v1...vn}\,k\texttt{))} \\
%        
        \llbracket \texttt{(match } e \texttt{(} p_1\,e_1\texttt{)}\ldots \texttt{(} p_n\,e_n\texttt{)} \rrbracket k
        =& \llbracket e \rrbracket \texttt{(fun (v) (case v }ps \,\texttt{)}\\
         & \text{where}\,ps = \texttt{(} p_1\,\llbracket e_1 \rrbracket k  \texttt{)}\ldots \texttt{(} p_n\,\llbracket e_n \rrbracket k \texttt{)}\\
%
        \llbracket \texttt{(error}\,s\,\texttt{)} \rrbracket k
        =& \texttt{(error}\,s\,\texttt{)} \\
   \end{align*}
    \caption{A call-by-value CPS translation}
    \label{fig:cps-translation}
\end{figure}

\begin{figure}
    \centering
\begin{lstlisting}
(def eval (env term k)
  (match term
    ([String x] (k (env x)))
    ({Abs x body}
      (k (fun (v k') (eval (extend env x v) body k'))))
    ({App fn arg}
      (eval env fn 
        (fun (fn') (eval env arg (fun (v) (fn' v k))))))))
    
(def extend (env x v) ...)
    
(def init (x) (error "empty environment"))
    
(def main ([Term term]) (eval init term (fun (x) x)))
\end{lstlisting}
    \caption{An interpreter for \LC{} in CPS}
    \label{fig:lambda-calc-interp-cps}
\end{figure}

\section{Defunctionalization}
The second step is the elimination of higher order functions from our interpreter, transforming it into a collection of mutually (tail-)recursive functions -- a state machine with the \texttt{main} function building initial configuration.
There are many approaches to compiling first class functions away but of particular interest to us will be defunctionalization.
It is a global program transformation that replaces each anonymous function definition with a uniquely labeled record which holds the values for function's free variables.
Every application of unknown function is replaced with a specific top-level \textit{apply} function which dispatches on the label of the passed record and evaluates the corresponding function's body.

This simple description glosses over many important details.
Firstly, we must distinguish between known and unknown function calls as only unknown calls should be transformed.
Secondly, we must be able to create records for top-level definitions when they are passed as a first class function, e.g., in the definition of \texttt{eval} in the branch for variables we apply an unknown function \texttt{env} which may evaluate either to an anonymous function created by \texttt{extend} or a top-level function \texttt{init}.
Lastly, we must somehow know for each application point which functions may be applied.
The first two challenges can be solved with a static, syntactic analysis of the interpreter.
The other challenge can be solved using control-flow analysis as described in Section \ref{sec:selective-defun}.
For the purposes of this example we observe that there are two function spaces with anonymous functions: continuations and environments.
The first is inhabited by th

\begin{figure}
    \centering
   \begin{align*}
        \llbracket \texttt{(f}\,e_1\ldots e_n\texttt{)@l} \rrbracket
        =& \texttt{(f}\,\llbracket e_1 \rrbracket \ldots \llbracket e_n \rrbracket \texttt{)}
         & \text{when}\,\texttt{f}\,\text{is top-level}\\
%
        \llbracket \texttt{(}\,e_1\ldots e_n\texttt{)@l} \rrbracket
        =& \texttt{(apply-l}\,\llbracket e_1 \rrbracket \ldots \llbracket e_n \rrbracket \texttt{)}
         & \text{otherwise}\\
%
        \llbracket \texttt{(fun (x ...)}\,e_l\texttt{)@l} \rrbracket
        =& \texttt{\{l y ...\}} & \\
        %  & \text{where \texttt{y ...} are free variables} & \\
%
        \llbracket \texttt{f} \rrbracket
        =& \texttt{\{lf\}} % & \\
        %  & \text{where \texttt{lf} is the label of top-level function \texttt{f}} &
   \end{align*}
    \caption{Defunctionalization algorithm}
    \label{fig:den-interp}
    \begin{verbatim}
(def apply-l (f x ...)
  (case f
    ({l-1 y-1 ...} e-1)
    ...
    ({l-n y-n ...} e-n)))
   \end{verbatim}
   \caption{Apply function template}
    \label{fig:den-template}
\end{figure}

Figure \ref{fig:den-interp} depicts an overview of defunctionalization procedure with \textit{apply} functions generated according to the template in Figure \ref{fig:den-template}.
We assume that every definition and expression in program has a unique label and that all generated names and structure labels are fresh. 
Whenever a top-level function is called the application is transformed into top-level call with the sub-expressions transformed.
Any other application is transformed into a call to \texttt{apply-l} where l is the application's label.
Anonymous functions are transformed into a labeled record with the function's free variables as sub-expressions.
Finally, references to top-level functions occurring in the program are transformed into labeled records.
The template in Figure \ref{fig:den-template} is instantiated as follows:
\begin{itemize}
    \item \texttt{l} is a label of application expression for which \texttt{apply-l} is generated
    \item \texttt{l-1} $\ldots$ \texttt{l-n} are labels of functions which may be applied in \texttt{l};
    \item \texttt{x ...} are variables bound by these functions (notice that it requires renaming of bound variables)
    \item (\texttt{y-1 ...}) $\ldots$ (\texttt{y-n ...}) are free variables of these functions
    \item \texttt{e-1} \ldots \texttt{e-n} are already transformed bodies of these functions
\end{itemize}
It is worth noting that defunctionalization preserves the tail-call property of a program in CPS.

Applying the defunctionalization procedure to the interpreter yields the definitions in Figure \ref{fig:defun-interp} having performed manual simplification and with carefully chosen names.
We can see that environments form a linked list of pairs variable-value and that the \texttt{lookup} function (which is a generated \textit{apply} function) searches this list for the first matching variable.
The defunctionalized continuations form a stack with \texttt{\{finish\}} at the bottom.
The generated \texttt{continue} function pops a frame from that stack and continues execution.
Evaluating function expression in defined language now produces a closure record which holds the environment and the name of the variable to be bound.
The machine we obtained is similar to the CEK \cite{Felleisen} machine but with explicit handling of environment extension and lookup.
\begin{figure}
    \centering
    \begin{verbatim}
(def extend (env x v k)
  (continue k {extend env x v}))

(def lookup (env y k)
  (case env
    ({extend env x v}
     (if (== x y) (continue k v) (lookup env y k)))
    ({init} (error "empty environment"))))

(def continue (k value)
  (case k
    ({eval-fun env e k} (eval e env {eval-app value k}))
    ({eval-app f k} (apply f value k))
    ({eval-body e k} (eval e value k))
    ({finish} value)))

(def apply (f v k)
  (case f 
    ({closure env x} (extend env x v {eval-body e k}))))

(def eval (e env k)
  (case e
    ({var x}   (lookup env x k))
    ({fun x e} (continue k {closure env x}))
    ({app f e} (eval f env {eval-fun env e k}))))
        
(def main (e) (eval e {init} {finish}))
    \end{verbatim}
    \caption{A defunctionalized interpreter}
    \label{fig:defun-interp}
\end{figure}
