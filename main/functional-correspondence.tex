\chapter{The Functional Correspondence}\label{chapter:functional-correspondence}
The functional correspondence between evaluators and abstract machines is a technique for mechanical derivation of an abstract machine from a given evaluator.\footnote{It may also be used in the other direction, i.e., to derive an interpreter corresponding to an abstract machine, by using inverse transformations.}
The technique was first characterized and described in \cite{functional-correspondence} and then later studied in context of various object-languages and their evaluators in \cite{ager-interpreter-compiler,ager-call-by-need,pirog-stg,biernacki-logic-engine,biernacka-delimited-continuations,ager-monadic-evaluators,danvy-object-oriented,jedynak-ltac}.
The input of the derivation is an evaluator written in some functional meta-language.
It usually corresponds to a variant of denotational semantics (particularly in case of so-called meta-circular interpreters) or big-step operational semantics.
The result of the derivation is a collection of mutually tail-recursive, first-order functions in the same meta-language.
Program in such a form corresponds to an abstract machine.
The different functions (with actual parameters) represent states of the machine, while the function calls specify the transition function.

The derivation consists of two program (in our case interpreter) transformations: transformation to continuation-passing style and defunctionalization.
The first one exposes the control structure of the evaluator; the second replaces function values with first-order data structures and their applications with calls to a first-order global function.

In the remainder of this chapter I will describe those transformations and illustrate their behavior using the running example of an evaluator for \LC{} from Section \ref{sec:idl}.
Let us recall the previously described meta-circular interpreter of Figure \ref{fig:lambda-calc-interp}.
The variables are represented as \lstinline!String!s of characters.
Since every closed expression in \LC{} may only evaluate to a function, the values produced by the interpreter are represented as meta-language functions.
The interpreter uses environments represented as partial functions from variables to values to handle binding of values to variables during application.
The application in the object-language is interpreted using application in the meta-language, so the defined language inherits call-by-value, left-to-right evaluation order.
At the end of this chapter we shall arrive at the CEK machine.

\section{Continuation-Passing Style}
The first step towards building the abstract machine is capturing the control-flow characteristics of the defined language.
We are interested in exposing the order in which the sub-expressions are evaluated and how the control is passed from function to function.
Additionally, we would like the resulting program to define a transition system so we must require that every function call in the interpreter is a tail-call.
It turns out that a program in continuation-passing style (CPS) exactly fits our requirements.

What does it mean for a program to be in CPS?
Let us begin by classifying expressions into trivial and serious ones.
An expression is trivial if evaluating it always returns a value.
Since we cannot in general decide whether an arbitrary expression is trivial we will use a safe approximation: an expression is trivial if it is a variable, a function definition, a primitive operation call or a structure constructor with only trivial expressions as sub-terms.
We will only allow applications, match expressions and constructors with trivial sub-expressions.
Additionally we would like to consider some expressions trivial due to their interpretation (e.g., environment lookups) even though they are serious.
In order to retain ability to build interesting programs, every function will accept an additional argument -- a continuation which specifies what should be done next.

The interesting clauses of the algorithm for simple CPS translation of expressions in \IDL{} are presented in Figure \ref{fig:cps-translation}.
The meta variables are typeset with italics (e.g., \textit{k}).
The pieces of syntax use typewriter font (e.g., \texttt{k'}).
The function $ \llbracket e \rrbracket k $ transforms an expression $e$ to continuation-passing-style using expression $k$ as a continuation.
Whenever a new variable is introduced by the algorithm we will assume that it is fresh.
The variable \texttt{x} is translated to application of continuation $k$ to \texttt{x}.
To translate an anonymous function definition, first a fresh variable \texttt{k'} is generated then the body of the function is translated with \texttt{k'} as the continuation and finally, the continuation $k$ is applied to the transformed function expression.
Function application is transformed by placing all sub-expressions in successively nested functions, with the deepest one actually performing the call with an additional argument -- the continuation $k$.
This way the evaluation of arguments is sequenced left-to-right and happens before the application.
Translation of the \lstinline{match} expression requires translating the scrutinee and putting the branches in the continuation. The branches are all transformed using the same continuation $k$.
Finally, during translation of the \texttt{error} expression the continuation is discarded since the error halts the execution.
The omitted rules for \texttt{if} expressions and record creation are similar to \texttt{match} expressions and applications, respectively.

Figure \ref{fig:lambda-calc-interp-cps} shows the interpreter with body of \lstinline!eval! translated to CPS using the algorithm of Figure \ref{fig:cps-translation} and then hand-optimized by reducing administrative redexes.
The \lstinline!eval! function now takes an additional argument \lstinline!k! -- a continuation.
The function denoting the object-language lambda expressions also expects a continuation.
In both variable and abstraction cases the evaluator now calls the continuation \lstinline!k! with the computed value: either looked up in the environment in case of a variable or freshly constructed in case of abstractions.
The evaluation of applications is now explicitly sequenced.
First the expression in function position will be evaluated.
It is passed a continuation which will then evaluate the argument.
After the argument is computed, the function value will be applied to the argument and the original continuation \lstinline!k! passed by the caller.
The \lstinline!main! function is kept in direct style as it is the entry point of the evaluator.
It calls the \lstinline!eval! function which expects a continuation so it provides it the identity function.
This continuation means that when evaluation is finished it will return the final value.

We can see that after the transformation the evaluation order of the meta-language does not affect the evaluation order of the object-language as every call to the only interesting function \lstinline!eval! is a tail call.
Therefore we have successfully captured control-flow characteristics of the object-language.
The evaluator still technically depends on the order of evaluation of \IDL{} as environment lookup may fail and it is in a sub-expression position but from the point of view of designing an abstract machine which works with closed terms it is not interesting.

In Section \ref{sec:selective-cps} we will see a more complex transformation which avoids creating administrative redexes and allows for user defined functions which should be considered trivial.

\begin{figure}
    \centering
   \begin{align*}
        \llbracket \lstinline{x} \rrbracket k =& \lstinline{(}k\,\lstinline{x)}\\
%
        \llbracket \lstinline!(fun ($x \ldots$)$\;e$)! \rrbracket k
        =& \lstinline{(} k \; \lstinline!(fun ($x \ldots$ k')!\, \llbracket \lstinline{e} \rrbracket \lstinline{k'))} \\
%        
        \llbracket \lstinline{(}e_1\ldots e_n\lstinline{)} \rrbracket k
        =& \llbracket e_1 \rrbracket \, \lstinline!(fun (v$_1$)! \bb{e_2}\lstinline!(fun$\;$($v_2$)! \ldots \llbracket e_n \rrbracket k' \lstinline!)$\ldots$)!\, \\
         & \text{where}\,k' = \lstinline!(fun (v$_n$)$\;$(v$_1 \ldots\;$v$_n$!\,k\lstinline!))! \\
%        
        \llbracket \lstinline!(match $\;e\;$ ($p\;e'$)$\ldots$)! \rrbracket k
        =& \llbracket e \rrbracket \lstinline!(fun (v)$\;$(match v\ !ps \lstinline!)!\\
        & \text{where}\,ps = \lstinline!(!p\;\llbracket e' \rrbracket k \lstinline!)! \ldots \\
%
%         \llbracket \lstinline{(error}\,s\,\lstinline{)} \rrbracket k
%         =& \lstinline{(error}\,s\,\lstinline{)}
   \end{align*}
    \caption{A call-by-value CPS translation}
    \label{fig:cps-translation}
\end{figure}

\begin{figure}
    \centering
\begin{lstlisting}
(def-data Term ...)

(def eval (env term k)
  (match term
    ([String x] (k (env x)))
    ({Abs x body}
      (k (fun (v k') (eval (extend env x v) body k'))))
    ({App fn arg}
      (eval env fn 
        (fun (fn') (eval env arg (fun (v) (fn' v k))))))))
    
(def extend (env x v) ...)
    
(def init (x) (error "empty environment"))
    
(def main ([Term term]) (eval init term (fun (x) x)))
\end{lstlisting}
    \caption{An interpreter for \LC{} in CPS}
    \label{fig:lambda-calc-interp-cps}
\end{figure}

\section{Defunctionalization}
The second step is the elimination of higher order functions from our interpreter, transforming it into a collection of mutually (tail-)recursive functions -- a state machine with the \lstinline{main} function building initial configuration.
There are many approaches to compiling first class functions away but of particular interest to us will be defunctionalization.
It is a global program transformation that replaces each anonymous function definition with a uniquely labeled record which holds the values for function's free variables.
Every application of unknown function is replaced with a specific top-level \textit{apply} function which dispatches on the label of the passed record and evaluates the corresponding function's body.

This simple description glosses over many important details.
Firstly, we must distinguish between known and unknown function calls as only unknown calls should be transformed.
Secondly, we must be able to create records for top-level definitions when they are passed as a first-class function, e.g., in the definition of \lstinline{eval} in the branch for variables we apply an unknown function \lstinline{env} which may evaluate either to an anonymous function created by \lstinline{extend} or a top-level function \lstinline{init}.
Lastly, we must somehow know for each application point which functions may be applied.
The first two challenges can be solved with a static, syntactic analysis of the interpreter.
The other challenge can be solved using control-flow analysis as described in Section \ref{sec:selective-defun}.
For the purposes of this example we observe that there are three function spaces with anonymous functions: continuations, representation of abstractions and environments.

\begin{figure}
    \centering
   \begin{align*}
        \llbracket \texttt{(f}\,e_1\ldots e_n\texttt{)@l} \rrbracket
        =& \texttt{(f}\,\llbracket e_1 \rrbracket \ldots \llbracket e_n \rrbracket \texttt{)}
         & \text{when}\,\texttt{f}\,\text{is top-level}\\
%
        \llbracket \texttt{(}\,e_1\ldots e_n\texttt{)@l} \rrbracket
        =& \texttt{(apply-l}\,\llbracket e_1 \rrbracket \ldots \llbracket e_n \rrbracket \texttt{)}
         & \text{otherwise}\\
%
        \llbracket \texttt{(fun (x ...)}\,e_l\texttt{)@l} \rrbracket
        =& \texttt{\{l y ...\}} & \\
        %  & \text{where \texttt{y ...} are free variables} & \\
%
        \llbracket \texttt{f} \rrbracket
        =& \texttt{\{lf\}} % & \\
        %  & \text{where \texttt{lf} is the label of top-level function \texttt{f}} &
   \end{align*}
    \caption{Defunctionalization algorithm}
    \label{fig:den-interp}
    \begin{verbatim}
(def apply-l (f x ...)
  (case f
    ({l-1 y-1 ...} e-1)
    ...
    ({l-n y-n ...} e-n)))
   \end{verbatim}
   \caption{Apply function template}
    \label{fig:den-template}
\end{figure}

Figure \ref{fig:den-interp} depicts an overview of defunctionalization procedure with \textit{apply} functions generated according to the template in Figure \ref{fig:den-template}.
We assume that every definition and expression in a program has a unique label and that all generated names and structure labels are fresh. 
Whenever a top-level function is called the application is transformed into top-level call with the sub-expressions transformed.
Any other application is transformed into a call to \texttt{apply-l} where \texttt{l} is the application's label.
Anonymous functions are transformed into a labeled record with the function's free variables as sub-expressions.
Finally, references to top-level functions occurring in the program are transformed into labeled records.
The template in Figure \ref{fig:den-template} is instantiated as follows:
\begin{itemize}
    \item \texttt{l} is a label of application expression for which \texttt{apply-l} is generated
    \item \texttt{l-1} $\ldots$ \texttt{l-n} are labels of functions which may be applied in \texttt{l}
    \item \texttt{x ...} are variables bound by these functions (notice that it requires renaming of bound variables)
    \item (\texttt{y-1 ...}) $\ldots$ (\texttt{y-n ...}) are free variables of these functions
    \item \texttt{e-1} \ldots \texttt{e-n} are already transformed bodies of these functions
\end{itemize}
It is worth noting that defunctionalization preserves the tail-call property of a program in CPS.
After applying the defunctionalization procedure to functions representing lambda abstractions and to continuations we obtain (again with a bit of manual cleanup) an encoding of the CEK machine \cite{Felleisen} in Figure \ref{fig:abstract-machine-cek}. 
It uses a stack \lstinline!Cont! (which are defunctionalized continuations) to handle the control-flow and \lstinline!Closure!s (which are defunctionalized lambda abstractions) to represent functions.
The environment is left untouched and is still encoded as a partial function.
The machine has two classes of states: \lstinline!eval! and \lstinline!continue!.
In \lstinline!eval! mode the machine dispatches on the shape of the term and either switches to \lstinline!continue! mode when it has found a value (either a variable looked up in the environment or an abstraction) or pushes a new continuation onto the stack and evaluates the expression in function position.
The \lstinline!continue! function is the \textit{apply} function generated by the defunctionalization procedure.
In \lstinline!continue! mode the machine checks the continuation and proceeds accordingly: when it reaches the bottom of the continuation stack \lstinline!Halt! it returns the final value \lstinline!val!; when the continuation is \lstinline!App1! it means that \lstinline!val! holds the function value which will be applied once \lstinline!arg! is computed; the stack frame \lstinline!App2! signifies that \lstinline!val! holds the computed argument and the machine calls a helper function \lstinline!apply! (the second generated \textit{apply} function) to unpack the closure in \lstinline!fn! and evaluate the body of the closure in the extended environment. 

\begin{figure}[hb]
\begin{lstlisting}
(def-data Term ...)

(def-data Cont
  {Halt}
  {App1 arg env cont}
  {App2 fn cont})

(def-struct {Closure body env x})

(def init (x) (error "empty environment"))
(def extend (env k v) ...)

(def eval (env term cont)
  (match term
    ([String x] (continue cont (env x)))
    ({Abs x body} (continue cont {Closure body env x}))
    ({App fn arg} (eval env fn {App1 arg env cont}))))

(def apply (fn v cont)
  (let {Fun body env x} fn)
  (eval (extend env x v) body cont))

(def continue (cont val)
  (match cont
    ({Halt} val))
    ({App1 arg env cont} (eval env arg {App2 val cont}))
    ({App2 fn cont} (apply fn val cont)))

(def main ([Term term]) (eval {Init} term {Halt}))
\end{lstlisting}
\caption{An encoding of the CEK machine for \LC{}}
\label{fig:abstract-machine-cek}
\end{figure}
