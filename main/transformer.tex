\chapter{Semantics Transformer}\label{chapter:transformer}
The adaptation of the functional correspondence into a semantics transformer was the main goal of this thesis.
Although the two main transformations considered here are widely known, they are not presented in literature in a form directly applicable for the task.
As the goal of the algorithm is to produce a definition of an abstract machine, to be read as a source code, care has to be taken to produce readable results.
To this end I chose to allow for partial CPS translation, with functions which should be left alone marked with annotations.
This approach allows one to specify helper functions whose control-flow is not particularly interesting to capture such as environment lookups.
The defunctionalization is usually presented as a manual transformation with human-specified function spaces or in a type directed fashion where all functions of a particular type end up in the same bag.
Neither of these approaches are satisfying for the purposes of a semantics transformer as the goal is to produce the result automatically and to uncover the operational properties of the evaluator.
Additionally I wanted to allow for partial defunctionalization of programs as it permits one to keep some parts of the machine abstract (e.g. functions modelling a heap or an environment).
I chose to employ the control-flow analysis to guide partitioning of function spaces as it approximates the runtime behavior of programs.
This approach allows for functions of the same type to land in different spaces based on their usage and it performed satisfactory in experiments I have conducted.
Finally, as the transformation generates new variables and moves code around we have to keep them readable.
To this end I both allow for (optional) program annotations and employ heuristics to guide generation of names for function records, introduced variables and functions.

The abstract syntax of \IDL{} is presented in Figure \ref{fig:idl-abs-syntax}.
The meta-variables $x, y, z$ denote variables; $r$ denote structure (aka record) names; $s$ is used to denote string literals and $b$ is used for all literal values -- strings, integers and booleans.
The meta-variable $\mathit{tp}$ is used in pattern matches which check whether a value is one of the primitive types.
The patterns are referred to with variable $p$ and may be a variable, a literal value, a wildcard, a record pattern or a type test.
Terms are denoted with variable $t$ and are one of variable, literal value, anonymous function, application, record constructor, let binding (which may destructure bound term with a pattern), pattern match or an error expression.

The transformation described in this chapter consists of three main stages: translation to administrative normal form, selective translation to continuation-passing style and selective defunctionalization.
After defunctionalization the program is in the desired form of an abstract machine.
The last step taken by the transformer is inlining of administrative let-bindings introduced by previous steps in order to obtain more readable results.
In the remainder of this chapter I will describe the three main stages of the transformation and the algorithm used to compute the control-flow analysis.


\begin{figure}
\begin{center}
\begingroup
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rrl}
  $x, y, z \in Var$ && $r\in StructName$\quad$s \in String$ \quad $b \in Int \cup Boolean \cup String$\\
  $Tp \ni \mathit{tp} $ &::=& \lstinline!String! | \lstinline!Integer! | \lstinline!Boolean!\\
  $Pattern \ni p $ &::=& $x$ | $b$ | \lstinline!_! | \lstinline!{$r$ $p\ldots$}! |  \lstinline![$\mathit{tp}$ $x$]!\\
  $Term \ni t$ &::=& $x$ | $b$
              | \lstinline!(fun ($x\ldots$) $t$)!
              | \lstinline!($t$ $t\ldots$)!
              | \lstinline!{$r$ $t\ldots$}!\\
              &|& \lstinline!(let $p$ $t$ $t$)!
              | \lstinline!(match $t$ ($p$ $t$)$\ldots$)!
              | \lstinline!(error $s$)!\\
  $FunDef \ni \mathit{fd}$ &::=& \lstinline!(def $x$ ($x\ldots$) $t$)!\\
  $StructDef \ni \mathit{sd}$ &::=& \lstinline!(def-struct {$r$ $x\ldots$})!\\
\end{tabular}
\endgroup
\end{center}
\caption{Abstract syntax of \IDL{}}\label{fig:idl-abs-syntax}
\end{figure}


\section{Administrative Normal Form}
The administrative normal form (ANF) \cite{flanagan-anf} is an intermediate representation for functional languages in which all intermediate results are let-bound to names.
This shape greatly simplifies later transformations as programs do not have complicated sub-expressions.
From operational point of view, the only place where a continuation is grown when evaluating program in ANF is a let-binding.
This property ensures that a program in ANF is also much easier to evaluate using an abstract machine which will be taken advantage of in Section \ref{sec:transformer-cfa}.
The abstract syntax of terms in ANF and an algorithm for transforming \IDL{} programs into such form is presented in Figure \ref{fig:transformer-anf}.
The terms are partitioned into three levels: variables, commands and expressions.
Commands $c$ extend variables with values -- base literals, record constructors (with variables as sub-terms) and abstractions (whose bodies are in ANF); and with redexes like applications of variables and match expressions (which match on variable and have branches in ANF).
Expressions $e$ in ANF have the shape of a possibly empty sequence of let-bindings ending with either an error term or a command.

The $\anf{\cdot}{\cdot}$ function, written in CPS, is the main transformation function.
Its arguments are term to be transformed and a meta-continuation (i.e. a continuation in meta-language) which will be called to obtain the term for the rest of transformed input.
This function decomposes the term according to the evaluation rules and uses two helper functions.
Function $\atomic{\cdot}$ transforms a continuation expecting an atomic expression (which are created when transforming commands) into one accepting any command by let-binding passed argument $c$ when necessary.
Function $\anfSeq{\cdot}{\cdot}$ sequences computation of multiple expressions by creating a chain of let-bindings (using $\atomic{\cdot}$) and then calling the continuation with created variables.

% TODO:
% - better characterization of the ANF
% - describe the algorithm
% - explain why this particular form

\begin{figure}
\begin{center}
\begingroup
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rll}
  $Command \ni c $ && ::= $x$ | $b$
  | \lstinline!(fun ($x\ldots$) $e$)!
  | \lstinline!($x$ $x\ldots$)!\\
  &&| \lstinline!{$r$ $x\ldots$}!
  | \lstinline!(match $x$ ($p$ $e$)$\ldots$)!\\
  $Expression \ni e $ && ::= $c$ 
  | \lstinline!(let $p$ $c$ $e$)!
  | \lstinline!(error $s$)!\\
  
  % $id\,x$ &&$= x$\\
  \hline\\
  $\bb{\cdot}$ &$\cdot$ &: $Expr \times (Com \rightarrow Anf) \rightarrow Anf$\\
  $\bb{a}$ &$k$ &$= k\,a$\\
  
  $\bb{\lstinline!(fun ($x\ldots$)\ $e$)!}$ &$k$
  & $= k\, \lstinline!(fun ($x\ldots$) $\anf{e}{id}$)!$\\
  
  $\bb{\lstinline!($e_f \; e_{arg}\ldots$)!}$ &$k$ 
  &$= \anf{e_f}{\atomic{\lambda a_f . \anfSeq{e_{arg}\ldots}{\lambda (a_{arg}\ldots) . k \,\lstinline!($a_f\;a_{arg}\ldots$)!}}}$\\

  $\bb{\lstinline!(let\ $x\;e_1\;e_2$)!}$ & $k$
  &$= \anf{e_1}{\lambda e_1' . \lstinline!(let\ $x\;e_1'\;\anf{e_2}{k}$)!}$\\

  $\bb{\lstinline!\{$r \; e\ldots$\}!}$ &$k$ 
  &$= \anfSeq{e\ldots}{\lambda (a\ldots) . k \,\lstinline!\{$r\;a\ldots$\}!}$\\

  $\bb{\lstinline!(match\ $e$\ ($p \;e_b$))!}$ & $k$
  &$= \anf{e}{\atomic{\lambda e' . k\,\lstinline!(match\ $e'\;$($p\;\anf{e_b}{id}$)!}}$\\

  $\bb{\lstinline!(error\ $s$)!}$ & \_ & $= $ \lstinline!(error $s$)!\\

  \hline\\
  $[\cdot]_a$ & $\cdot$ & : $(Atomic \rightarrow Anf) \rightarrow Com \rightarrow Anf$\\
  $[k]_a$ & $a$ & $= k\,a$\\
  $[k]_a$ & $c$ & $= $ \lstinline!(let $x$ $c$ $(k\,x)$)!\\
  \hline\\
  $\bb{\cdot}_s$ & $\cdot$ &: $Expr^* \times (Atomic^* \rightarrow Anf) \rightarrow Anf$\\
  $\bb{e\ldots}_s$ & $k$ & $= \bb{e\ldots}_s^{\epsilon}$\\
  $\bb{\epsilon}_s^{a\ldots}$ & $k$ & $= k\,(a\ldots)$\\
  $\bb{e\,e_r\ldots}_s^{a_{acc}\ldots}$ & $k$ & 
  $= \anf{e}{\atomic{\lambda a . \bb{e_r\ldots}_s^{a_{acc}\ldots a}}}$

\end{tabular}
\endgroup
\end{center}
\caption{ANF transformation for \IDL{}}
\label{fig:transformer-anf}
\end{figure}


\section{Control-Flow Analysis}\label{sec:transformer-cfa}
The analysis most relevant to the task of deriving abstract machines from interpreters is the control-flow analysis.
Its objective is to find for each expression in a program an over-approximation of a set of functions it may evaluate to \cite{popa}.
This information can be used in two places: when determining whether a function and applications should be CPS transformed and for checking which functions an expression in operator position may evaluate to.
There are a couple of different approaches to performing this analysis available in the literature: abstract interpretation \cite{popa}, (annotated) type systems \cite{popa} and abstract abstract machines \cite{aam}.
I chose to employ the last approach as it allows for derivation of the control-flow analysis from an abstract machine for \IDL{}.
The derivation technique guarantees correctness of the resulting interpreter and hence provides high confidence in the actual implementation of the machine.
I will present the template for acquiring both concrete and abstract versions of the abstract machine for \IDL{} but refrain from stepping through the whole derivation.
An interested reader should definitely acquaint themselves with the original work in \cite{aam} to understand the reasoning and insights behind the technique.

\subsection*{A Machine Template}
We will begin with a template of a machine for \IDL{} terms in A-normal form presented in Figure \ref{fig:anf-abstract-machine}.
It is a CEK-style machine modified to explicitly allocate memory for values and continuations in an abstract store.
The template is parameterized by: implementation of the store $\sigma$ along with five operations: $\mathit{alloc}_v$, $\mathit{alloc}_k$, $\mathit{deref}_v$, $\mathit{deref}_k$ and $\mathit{copy}_v$; interpretation of primitive operations $\delta$ and implementation of $\mathit{match}$ function which interprets pattern matching.
The store maps value addresses $\nu$ to values $v$ and continuation addresses $\kappa$ to continuations $k$.
The environment maps program variables to value locations.
The values on which machine operates are the following: base values $b$, primitive operations $\delta$, records with addresses as fields, closures and top-level functions.
Thanks to terms being in A-normal form, there are only two kinds of continuations which form a stack.
The stack frames $\tuple{\rho, p, e, \kappa}$ are introduced by let-bindings. They hold an environment $\rho$, a pattern $p$ to use for destructuring of a value, the body $e$ of a let expression and a pointer to the next continuation $\kappa$.
The bottom of the stack is marked by the empty continuation $\tuple{}$.
We assume that every term has a unique label $l$ which will be used in abstract version of the machine to implement store addresses.

The machine configurations are pairs of a store $\sigma$ and a partial configuration $\gamma$.
This split of configuration into two parts will prove beneficial when we will be instantiating the template to obtain an abstract interpreter.
There are two classes of partial configurations.
An evaluation configuration contains an environment $\rho$, an expression $e$ and a continuation pointer $\kappa$.
A continuation configuration holds an address $\nu$ of a value that has been computed so far and a pointer $\kappa$ to a resumption which should be applied next.

The first case of the transition relation $\Rightarrow$ looks up a pointer for the variable $x$ in the environment $\rho$ and switches to the continuation mode.
It modifies the store via $\mathit{copy}$ function which ensures that every occurrence of a variable has a corresponding binding in the store.
The next three cases deal with values by $\mathit{alloc}$ating them in the store and switching to the continuation mode.
When the machine encounters a let-binding it allocates a continuation for the body $e$ of the expression and proceeds to evaluate the bound command $c$ with the new pointer $\kappa'$.
In case of applications and match expressions the resulting configuration is decided using auxiliary functions $\mathit{apply}$ and $\mathit{match}$ respectively.
Finally, in continuation mode, may transition if the continuation loaded from address $\kappa$ is a frame.
In such a case the machine matches the stored pattern against the value pointed-to by $\nu$.
Otherwise $\kappa$ points to a $\tuple{}$ instead and the machine has reached the final state.
The auxiliary function $\mathit{apply}$ checks what kind of function is referenced by $\nu$ and proceeds accordingly.

\begin{figure}[ht]
\begin{center}
\begingroup
\begin{tabular}{rl}
$\nu \in \VA{}$ & $\kappa \in \KA{}\quad l \in \mathit{Label}$\quad$\sigma \in \mathit{Store}$\\

$\delta \in \mathit{PrimOp}$ & $\subseteq \mathit{Val}^* \rightarrow Val$\\

$\rho \in \mathit{Env}$ &$= \mathit{Var} \rightarrow \VA{}$\\

$\mathit{Val} \ni v$ 
& ::= $b$ | $\delta$ 
    | \lstinline!{$r\;\nu\ldots$}!
    | $\tuple{\rho,x\ldots,e}$
    | \lstinline!(def $x$ ($x\ldots$) $e$)!\\

$\mathit{Cont} \ni k$ & ::= $\tuple{\rho, p, e, \kappa}$ | $\tuple{}$\\

$\mathit{PartialConf} \ni \gamma $
& ::= $\tuple{\rho, e, \kappa}_e $ | $\tuple{\nu, \kappa}_c$\\

$\mathit{Conf} \ni \varsigma $
& ::= $\tuple{\sigma, \gamma}$\\
\end{tabular}

\begin{tabular}{|rl|}
\hline
$\tuple{\sigma, \tuple{\rho, x, \kappa}_e}$
& $\Rightarrow \tuple{\mathit{copy}_v(\rho(x), l, \sigma), \tuple{\rho(x), \kappa}_c}$\\

$\tuple{\sigma, \tuple{\rho, b^l, \kappa}_e}$
& $\Rightarrow \tuple{\sigma', \tuple{\nu, \kappa}_c}$\\
& where $\tuple{\sigma', \nu} = \mathit{alloc}_v(b, l, \sigma)$\\

$\tuple{\sigma, \tuple{\rho, \lstinline!\{$r\;x\ldots$\}!^l, \kappa}_e}$
& $\Rightarrow \tuple{\sigma', \tuple{\nu, \kappa}_c}$\\
& where $\tuple{\sigma', \nu} = \mathit{alloc}_v(\lstinline!{$r\;\rho(x)\ldots$}!, l, \sigma)$\\

$\tuple{\sigma, \tuple{\rho, \lstinline!(fun ($x\ldots$)\ $e$)!^l, \kappa}_e}$
& $\Rightarrow \tuple{\sigma', \tuple{\nu, \kappa}_c}$\\
& where $\tuple{\sigma', \nu} = \mathit{alloc}_v(\tuple{\rho, x\ldots, e}, l,\sigma)$\\

$\tuple{\sigma, \tuple{\rho, \lstinline!(let\ $p\;c^l\;e$)!, \kappa}_e}$
& $\Rightarrow \tuple{\sigma', \tuple{\rho, c, \kappa'}_e}$\\
& where $\tuple{\sigma', \kappa'} = \mathit{alloc}_k(\tuple{\rho, p, e, \kappa}, l, \sigma)$\\

$\tuple{\sigma, \tuple{\rho, \lstinline!($x\;y\ldots$)!, \kappa}_e}$
& $\Rightarrow \mathit{apply}(\sigma, \rho(x), \rho(y)\ldots, l)$\\

$\tuple{\sigma, \tuple{\rho, \lstinline!(match\ $x\;$($p\;e$)$\ldots$)!, \kappa}_e}$
& $\Rightarrow \mathit{match}(\sigma, \rho, \rho(x), \tuple{p, e}\ldots)$\\

$\tuple{\sigma, \tuple{\nu, \kappa}_c}$
& $\Rightarrow \mathit{match}(\sigma, \rho, \nu, \kappa', \tuple{p, e})$\\
& where $\tuple{\rho, p, e, \kappa'} = \mathit{deref}_k(\sigma, \kappa)$\\[2pt]

% \hline &\\[\dimexpr-\normalbaselineskip+2pt]
\hline

$ \mathit{apply}(\sigma, \nu, \nu'\ldots, \kappa, l)$
& $ = \begin{cases}
  \tuple{\sigma, \tuple{\rho[(x \mapsto \nu') \ldots], e, \kappa}_e}\\
  \quad\text{when}\;\mathit{deref}_v(\sigma, \nu) = \tuple{\rho, x\ldots, e}\\

  \tuple{\sigma, \tuple{\rho_0[(x \mapsto \nu') \ldots], e, \kappa}_e}\\
  \quad\text{when}\;\mathit{deref}_v(\sigma, \nu) = \lstinline!(def $y\;$($x\ldots$) $e$)!\\

  \tuple{\sigma', \tuple{\nu'', \kappa}_c}\\
  \quad\text{when}\;\mathit{deref}_v(\sigma, \nu) = \delta\\
  \quad\text{and}\;\tuple{\sigma', \nu''} = \mathit{alloc}_v(\delta(\sigma(\nu')\ldots), l, \sigma)
\end{cases} $ \\

$ \mathit{match}(\sigma, \rho, \nu, \kappa, \tuple{p, e}\ldots)$
& $= \tuple{\sigma, \tuple{\rho', e', \kappa}_e}$ where $\rho'$ is the environment\\
&\quad for the first matching branch with body $e'$\\
\hline
\end{tabular}
\endgroup
\end{center}
\caption{An abstract machine for \IDL{} terms in ANF}
\label{fig:anf-abstract-machine}
\end{figure}

\subsection*{A Concrete Abstract Machine}
The machine template can now be instantiated with a store, a $\mathit{match}$ implementation which finds the first matching branch and interpretation for primitive operations in order to obtain an abstract machine.
By choosing $\mathit{Store}$ to be a mapping with infinite domain we can ensure that $\mathit{alloc}$ can always return a fresh address.
In this setting the store-allocated continuations are just an implementation of a stack.
The extra layer of indirection introduced by storing values in a store can also be disregarded as the machine operates on persistent values.
Therefore the machine corresponds to a CEK-style abstract machine which is a natural \cite{functional-correspondence} formulation for call-by-value functional calculi.

\subsection*{An Abstract Abstract Machine}\label{ss:aam}
Let us now turn to a different instantiation of the template.
Figure \ref{fig:aam} shows the missing pieces of an abstract abstract machine for \IDL{}.
The abstract values use base type names $tp$ to represent any value of that type, abstract versions of primitive operations, records, closures and top-level functions.
The interpretation of primitive operations must approximate their concrete counterparts.

The store is represented as a pair of finite mappings from labels to sets of abstract values and continuations respectively.
This bounding of store domain and range ensures that the state-space of the machine becomes finite and therefore can be used for computing an analysis.
To retain soundness w.r.t. the concrete abstract machine the store must map a single address to multiple values to account for address reuse.
This style of abstraction is fairly straightforward as noted by \cite{aam} and used in textbooks \cite{popa}.
When instantiated with this store, the transition relation $\Rightarrow$ becomes nondeterministic as pointer $\mathit{deref}$erencing nondeterministically returns one of the values available in the store.
Additionally the implementation of $\mathit{match}$ function is also nondeterministic in choice of a branch to match against.
This machine is not yet suitable for computing the analysis as the state space is still too large since every machine configuration has its own copy of the store.
To circumvent this problem a standard technique of widening \cite{popa} can be employed.
In particular, following \cite{aam}, we will use a global store.
The abstract configuration $\tilde{\varsigma}$ is a pair of a store and a set of partial configurations.
The abstract transition $\Rightarrow_a$ performs one step of computation using $\Rightarrow$ on the global store $\sigma$ paired with every partial configuration $\gamma$.
The resulting stores $\sigma'$ are merged together and with the original store to create a new, extended global store.
The partial configurations $C'$ are added to the initial set of configurations $C$.
The transition relation $\Rightarrow_a$ is deterministic so it can be treated as a function.
This function is monotone on a finite lattice and therefore is amenable to fixed-point iteration.

\begin{figure}
\begin{center}
\begingroup
\begin{tabular}{rl}
$\VA{}$ & $=\KA{}=\mathit{Label}$\\
$\widetilde{\mathit{Val}} \ni v$ 
& ::= $tp$ | $\widetilde{\delta}$
    | \lstinline!{$r\;\nu\ldots$}!
    | $\tuple{\rho,x\ldots,e}$
    | \lstinline!(def $x$ ($x\ldots$) $e$)!\\

$\sigma \in \mathit{Store} $
& $= (\VA{} \rightarrow \mathbb{P}(\widetilde{\mathit{Val}}))
  \times (\KA{} \rightarrow \mathbb{P}(\mathit{Cont}))$\\

$\mathit{alloc}_v(v, l, \tuple{\sigma_v, \sigma_k})$ 
& $= \tuple{\tuple{\sigma_v[l \mapsto \sigma_v(l)\cup\{v\}], \sigma_k}, l}$\\

$\mathit{alloc}_k(v, l, \tuple{\sigma_v, \sigma_k})$
& $= \tuple{\tuple{\sigma_v, \sigma_k[l \mapsto \sigma_k(l)\cup\{k\}]}, l}$\\

$\mathit{copy}_v(\nu, l, \tuple{\sigma_v, \sigma_k})$
& $= \tuple{\sigma_v[l \mapsto \sigma_v(l)\cup\sigma_v(\nu)], \sigma_k}$\\

$\mathit{deref}_v(l, \tuple{\sigma_v, \sigma_k})$ 
& $= \sigma_v$\\


$\tilde{\varsigma} \in \widetilde{\mathit{Conf}}$
& $ = Store\times\mathbb{P}(PartialConf)$\\
\hline
$\tuple{\sigma, C}$ 
& $\Rightarrow_a \tuple{\sigma'\sqcup\sigma, C\cup C'}$\\
& where $\sigma' = \bigsqcup\{\sigma' \mid \exists \gamma \in C. \tuple{\sigma, \gamma} \Rightarrow \tuple{\sigma', \gamma'} \}$\\
& and $C' = \{\gamma' \mid \exists \gamma \in C. \tuple{\sigma, \gamma} \Rightarrow \tuple{\sigma', \gamma'} \}$\\
\hline

\end{tabular}
\endgroup
\end{center}
\caption{An abstract abstract machine for \IDL{}}
\label{fig:aam}
\end{figure}

\subsection*{Computing the Analysis}
With the abstract transition function in hand we can now specify the algorithm for obtaining the analysis.
To start the abstract interpreter we must provide it with an initial configuration: a store, an environment, a term and a continuation pointer.
The store will be assembled from datatype and structure definitions of the program as well as base types.
The initial term is the body of the \lstinline!main! function of the interpreter and the environment is the global environment extended with \lstinline!main!'s parameters bound to pointers to datatypes in the above-built store.
The initial continuation is of course $\tuple{}$ and the pointer is the label of the \lstinline!main!'s body.
The analysis is computed by performing fixed-point iteration of $\Rightarrow_a$.
The resulting store will contain a set of functions to which every variable (the only allowed term) in function position may evaluate to (ensured by the use of $\mathit{copy}_v$ function).
This result will be used in Sections \ref{sec:selective-cps} and \ref{sec:selective-defun}.

\section{Selective CPS}\label{sec:selective-cps}
In this section we will formulate an algorithm for selectively transforming the program into continuation-passing style.
All functions (anonymous and top-level) marked \lstinline!#:atomic! by the user will be kept in direct style.
The \lstinline!main! function is implicitly marked as atomic since its interface should be preserved as it is an entry point of the interpreter.
Primitive operations are treated as atomic at call-site.
Atomic functions may call non-atomic ones by providing the called function an identity continuation.
The algorithm uses the results of control-flow analysis to determine whether all functions to which a variable labeled $l$ in function position may evaluate are atomic -- denoted $\allAtomic(l)$ or none of them are atomic -- $\noneAtomic(l)$.
When both atomic and non-atomic functions may be called the algorithm cannot proceed and signals an error in the source program.

The algorithm consists of two mutually recursive transformations: $\cps{e}{k}$ in Figure \ref{fig:cps-cps} transforming a term $e$ into CPS with a program variable $k$ as a continuation and $\dir{e}$ in Figure \ref{fig:cps-direct} transforming a term $e$ which should be kept in direct style.

The first five clauses of CPS translation deal with values.
When a variable is encountered it may be immediately returned by applying continuation.
In other cases the value must be let-bound in order to preserve the A-normal form of the term and then the continuation is applied to the introduced variable.
The body $e$ of an anonymous function is translated using $\dir{e}$ when the function is marked atomic.
When the function is not atomic a new variable $k'$ is appended to its parameter list and its body is translated using $\cps{e}{k'}$.
The form of an application depends on atomicity of functions which may be applied.
When none of them are atomic the continuation $k$ is passed to the function.
When all of them are atomic the result of the call is let-bound and returned by applying the continuation $k$.
Match expression is transformed by recursing on its branches.
Since the continuation is always a program variable no code gets duplicated.
When transforming a let expression the algorithm checks whether the bound command $c$ is $\trivial$ -- meaning it will only call atomic functions when evaluated.
If it is then it can remain in direct style $\dir{c}$, no new continuation has to be introduced and the body can be transformed by $\cps{e}{k}$.
If the command is non-trivial then a new continuation is created and bound to $k'$.
This continuation uses the variable $x$ as its argument and its body is the body of let-expression $e$ transformed with the input continuation $k$.
The bound command is transformed with the newly introduced continuation $k'$.
Finally, the translation of \lstinline!error! throws out the continuation.

The direct style transformation begins similarly to CPS one -- with five clauses for values.
In case of an application the algorithm is symmetric: when all functions are atomic the call remains in direct style, when none of them are atomic a new identity continuation $k$ is constructed and is passed to the called function.
A match expression is again transformed recursively.
A let binding of a call to cps function gets special treatment to preserve A-normal by chaining allocation of identity continuation with the call.
In other cases a let binding is transformed recursively.
An \lstinline!error! expression is left untouched.

Each top-level function definition in a program is transformed in the same fashion as anonymous functions.
After the transformation the program is still in ANF and can be again analyzed by the abstract abstract machine of previous section. 
\begin{figure}[]
\centering
\begin{tabular}{rl}
  $\cps{x}{k}$ &= \lstinline!($k$ $x$)!\\
  
  $\cps{b}{k}$ &= \lstinline!(let $x$ $b$ ($k$ $x$))!\\
  
  $\cps{\lstinline!\{$r\;x\ldots$\}!}{k}$
  &= \lstinline!(let $y$ {$r\;x\ldots$} ($k$ $y$))!\\

  $\cps{\lstinline!(fun #:atomic ($x\ldots$)\ $e$)!}{k}$
  &= \lstinline!(let $y$ (fun ($x\ldots$) $\dir{e}$) ($k$ $y$))!\\

  $\cps{\lstinline!(fun ($x\ldots$)\ $e$)!}{k}$
  &= \lstinline!(let $y$ (fun ($x\ldots k'$) $\cps{e}{k'}$) ($k$ $y$))!\\

  $\cps{\lstinline!($f^l\;x\ldots$)!}{k}$
  &= $ \begin{cases}
    \lstinline!($f$ $x\ldots$ $k$)! & \mathrm{when}\,\noneAtomic(l)\\
    \lstinline!(let $y$ ($f$ $x\ldots$) ($k$ $y$))! & \mathrm{when}\,\allAtomic(l)\\
  \end{cases} $\\

  $\cps{\lstinline!(match$\;x\;$($p\;e$)$\ldots$)!}{k}$
  &= \lstinline!(match $x$ ($p$ $\cps{e}{k}$)$\ldots$)!\\

  $\cps{\lstinline!(let$\;x\;c\;e$)!}{k} $
  &= $ \begin{cases}
    \lstinline!(let $x$ $\dir{d}$ $\cps{e}{k}$)! &\mathrm{when}\,\trivial(c)\\
    \lstinline!(let $k'$ (fun ($x$) $\cps{e}{k}$) $\cps{c}{k'}$)! &\mathrm{otherwise}
  \end{cases}$\\

  $\cps{\lstinline!(error$\;s$)!}{k}$ &= \lstinline!(error $s$)!
\end{tabular}
\caption{A translation for CPS terms}
\label{fig:cps-cps}
\end{figure}

\begin{figure}[]
\centering
\begin{tabular}{rl}
  $\dir{x}$ &= $x$\\
  
  $\dir{b}$ &= $b$\\
  
  $\dir{\lstinline!\{$r\;x\ldots$\}!}$
  &= \lstinline!{$r\;x\ldots$}!\\

  $\dir{\lstinline!(fun #:atomic ($x\ldots$)\ $e$)!}$
  &= \lstinline!(fun ($x\ldots$) $\dir{e}$)!\\

  $\dir{\lstinline!(fun ($x\ldots$)\ $e$)!}$
  &= \lstinline!(fun ($x\ldots k'$) $\cps{e}{k'}$)!\\

  $\dir{\lstinline!($f^l\;x\ldots$)!}$
  &= $ \begin{cases}
    \lstinline!($f$ $x\ldots$)! & \mathrm{when}\,\allAtomic(l)\\
    \lstinline!(let $k$ (fun ($y$) $y$) ($f$ $x\ldots$ $k$))! & \mathrm{when}\,\noneAtomic(l)\\
  \end{cases} $\\

  $\dir{\lstinline!(match$\;x\;$($p\;e$)$\ldots$)!}$
  &= \lstinline!(match $x$ ($p$ $\dir{e}$)$\ldots$)!\\

  $\dir{\lstinline!(let$\;x\;$($f^l\;y\ldots$)$\;e$)!}$
  &= \begin{lstlisting}
(let $k$ (fun ($z$) $z$)
  (let $x$ ($f$ $y\ldots$ $k$))
    $\dir{e}$)
  \end{lstlisting}\quad when $\noneAtomic(l)$\\

  $\dir{\lstinline!(let$\;x\;c\;e$)!}$
  &= \lstinline!(let $x$ $\dir{c}$ $\dir{e}$)!\\

  $\dir{\lstinline!(error$\;s$)!}$ &= \lstinline!(error $s$)!
\end{tabular}
\caption{A translation for direct style terms}
\label{fig:cps-direct}
\end{figure}

\begin{figure}[]
\centering
\begin{align*}
  \trivial(x) &\quad\trivial(b)\\
  trivial(\lstinline!(\{$r\;x\ldots$\})!)
  &\quad\trivial(\lstinline!(fun ($x\ldots$)\ $e$)!)\\
%
  \trivial(\lstinline!($f^l\;x\ldots$)!) &\iff \allAtomic(l)\\
%
  \trivial(\lstinline!(match $\;x\;$($b\;e$)$\ldots$)!)%
  &\iff \bigwedge\trivial(e)\ldots\\
%
  \trivial(\lstinline!(let$\;x\;c\;e$)!)%
  &\iff \trivial(c) \wedge \trivial(e)
\end{align*}
\caption{The $\trivial$ predicate}
\label{fig:cps-trivial}
\end{figure}


\section{Selective Defunctionalization}\label{sec:selective-defun}
The second step of the functional correspondence and the last stage of the transformation is selective defunctionalization.
The goal is to defunctionalize function spaces deemed interesting by the author of the program.
To this end top-level and anonymous functions may be annotated with \lstinline!#:no-defun! to skip defunctionalization of function spaces they belong to.
In the algorithm of Figure \ref{fig:defun} the predicate $\defun$ specifies whether a function should be transformed.
Predicates $\mathit{primOp}$ and $\mathit{topLevel}$ specify whether a variable refers to (taking into account the scoping rules) primitive operation or top-level function respectively.
For each application point $l$ in the program we can utilize the results of control-flow analysis to obtain the set of functions which may be applied.
If all of them should be defunctionalized ($\mathit{allDefun}$) then a call to the generated apply function is introduced, when none of them should ($\mathit{noneDefun}$) then the application is left as is, if neither condition holds then an error in the source program is signaled.
The apply functions are generated using $\mkApply$ as specified in Figure \ref{fig:defun-apply} where the $\mathit{fn}\ldots$ is a list of functions which may be applied.
After the transformation the program is no longer in A-normal form since variables referencing top-level functions may have been transformed into records.
However it does not pose a problem since the majority of work has already been done and the last step -- let-inlining does not require the program to be in ANF.



\begin{figure}
\centering
\begin{tabular}{rl}

  $\bb{x}$ &= $ \begin{cases}
    \lstinline!{Prim$_x$}! & \mathrm{when}\,\mathit{primOp}(x)\\
    % x\text{is a reference to prim op}\\
    \lstinline!{Top$_x$}!  & \mathrm{when}\,\mathit{topLevel}(x)\\
    % x\text{is a reference to a top-level function which should be defunctionalized}\\
    x & \mathrm{otherwise}
  \end{cases} $\\

  $\bb{b}$ &= $b$\\
  
  $\bb{\lstinline!\{$r\;x\ldots$\}!}$
  &= \lstinline!{r $\bb{x}\ldots$}!\\

  $\bb{\lstinline!(fun\ ($x\ldots$)\ $e$)$^l$!}$
  &= $\begin{cases}
    \lstinline!{Fun$_l$ $\mathit{fvs}(e)$}! &\text{when }\defun(l)\\
    \lstinline!(fun ($x\ldots$) $\bb{e}$)! &\text{otherwise}
  \end{cases}$\\

  $\bb{\lstinline!(!f^{l'}\;x\ldots\lstinline!)!^l}$
  &= $\begin{cases}
    \lstinline!(apply$_l$ $f$ $\bb{x}\ldots$)! &\text{when }\mathit{allDefun}(l')\\
    \lstinline!($f\;\bb{x}\ldots$)! &\text{when }\mathit{noneDefun}(l')
  \end{cases}$\\

  $\bb{\lstinline!(match$\;x\;$($p\;e$)$\ldots$)!}$
  &= \lstinline!(match $x$ ($p$ $\bb{e}$)$\ldots$)!\\

  $\bb{\lstinline!(let$\;x\;c\;e$)!}$
  &= \lstinline!(let $x$ $\bb{c}$ $\bb{e}$)!\\

  $\bb{\lstinline!(error$\;s$)!}$ &= \lstinline!(error $s$)!
\end{tabular}
\caption{Selective defunctionalization algorithm for \IDL{}}
\label{fig:defun}
\end{figure}

\begin{figure}
\centering
\begingroup
\setlength{\tabcolsep}{2pt}
\begin{tabular}{rrl}
  $\mkBranch(x\ldots,$&$\delta)$
  &= \lstinline!({Prim$_\delta$} ($\delta\;x\ldots$))!\\

  $\mkBranch(x\ldots,$&$\lstinline!(def $f$ ($y\ldots$) e)!)$
  &= \lstinline!({Top$_f$} ($f$ $x\ldots$))!\\

  $\mkBranch(x\ldots,$&$\lstinline!(fun ($y\ldots$) $e$)$^l$!)$
  &= \lstinline!({Fun$_l$ $\mathit{fvs}(e)$} $\bb{e}[y\mapsto x]$)!\\
\end{tabular}
\begin{tabular}{rl}
  $\mkApply(l, \mathit{fn} \ldots)$
  &= \begin{lstlisting}
(def apply$_l$ ($f$ $x\ldots$)
  (match $f$
    $\mkBranch(x\ldots, \mathit{fn})\ldots$))
  \end{lstlisting}
\end{tabular}
\endgroup
\caption{Top-level apply function generation}
\label{fig:defun-apply}
\end{figure}
